\documentclass[12 pt]{article}
\usepackage{easycalc3}
\usepackage{setspace}
\usepackage{enumerate}
\usepackage{lastpage}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{tabularx}
\usepackage{ltablex}
\usepackage{textcomp}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage[margin=1 in]{geometry}
\allowdisplaybreaks
%\usepackage[dvipsnames]{xcolor}   %May be necessary if you want to color links
\usepackage{graphicx}
\graphicspath{{Images/}}
\author{Sarah Randall}
\date{Last updated: \today}
\title{MATH 222: Week 1}
\pagestyle{fancy}
\lhead{MATH 222}
\chead{\leftmark}
\rhead{Sarah Randall}
\cfoot{Page \thepage \ of \pageref{LastPage}}
\newcommand{\tab}[1]{\hspace{.2\textwidth}\rlap{#1}}
\begin{document}
	\onehalfspacing
	\maketitle
	\tableofcontents
	\section{\S 11.1 Sequences}
		A sequence $\{a_n\}_{n=1}^{\infty}$ can be thought of as a an infinite
		list of numbers. Often they are generated by a function $a_n=f(n)$.\\
		\begin{exmp*}
			\begin{align*}
				&a_n=f(n)=\frac{n+1}{n}
				\\a_1&=2,\ a_2=\frac{3}{2},\ a_3=\frac{4}{3},\ ...
			\end{align*}
		\end{exmp*}
		A sequence can also be defined recursively (like the Fibonacci sequence)
		but we won't use those much.\\\\
		Thinking of $a_n$ as a function $f(n):N\rightarrow R$ can be useful
		when studying the limit for large $n$.
		\begin{def*}
			A sequence converges to limit $L$ written:
			\begin{center}
				$\Lim{n\toinfty} a_n=L$
			\end{center}
			if for every $\varepsilon>0\ \exists$ a corresponding $N$ such that
			$\left|a_n-L\right| < \varepsilon \forall N$
		\end{def*}
		\begin{def*}
			We say that a sequence diverges as $n\toinfty$ if is not
			convergent. This includes if $\Lim{n\toinfty}a_n=\pm\infty$
		\end{def*}
		\begin{exmp*}
			$\Lim{x\toinfty}sin(x)$ diverges because its value constantly
			changes. $\Lim{x\toinfty}e^x$ diverges as well because it
			keeps increasing up to $+\infty$. There are difference types of divergence.
		\end{exmp*}
		\begin{exmp*}
			Prove that $a_n=(-1)^n$ diverges
			\\Suppose that $\Lim{n\toinfty} a_n=L$ exists. But this means
			that consecutive terms must get closer together, therefore\\
			$$\lim_{n\toinfty}\left|a_n-a_{n+1}\right|=0$$
			if this assumption is true. However,
			$$\lim_{n\toinfty}\left|(-1)^n-(-1)^{n+1}\right|=2$$
			and not 0. $\therefore a_n=(-1)^n$ diverges.\\
		\end{exmp*}

		\subsection{Proving a series converges}
		\begin{thrm}
			If $\Lim{n\toinfty}f(x)=L$ for $x\in\R$ and if $f(n)=a_n$,
			then $\Lim{n\toinfty}a_n=L$
		\end{thrm}

		\begin{remark}
			If $\Lim{x\toinfty}f(x)$ diverges then this DOES NOT imply that
			$a_n=f(n)$ diverges.
		\end{remark}
		\begin{exmp*}
			$\Lim{n\toinfty}sin(\pi x)$ diverges clearly, but
			$\Lim{n\toinfty}sin(\pi x) = 0$ and this sequence converges.
			When you change from $\R$ to $\N$ you might get different results.
		\end{exmp*}

		\subsection{Sequence limit laws}

		Suppose $\{a_n\},\{b_n\}$ are convergent sequences with $\Lim{n\toinfty}
		a_n=A$ and $\Lim{n\toinfty}b_n=B$. Then:
		\begin{center}$\Lim{n\toinfty}(a_n+b_n)=A+B$\\
			$\Lim{n\toinfty}(a_n-b_n)=A-B$\\
			$\Lim{n\toinfty}c*a_n=c*A\ ,\ c\in\R$
		\end{center}
		\begin{thrm}If $f(x)$ is a continuous function and $\Lim{n\toinfty}a_n=L$,
			then\\ $$\lim_{n\toinfty}f(a_n)=f(\lim_{n\toinfty}a_n)=f(L)$$
		\end{thrm}
		\begin{exmp*}
			$a_n=(\frac{1}{n})^{10}$\\
			Take $f(x)=x^{10}$ so then $f(\frac{1}{n})=(\frac{1}{n})^{10}$\\
			Since $f(x)=x^{10}$ is continuous:
			$$\lim_{n\toinfty}(\frac{1}{n})^{10}=\lim_{n\toinfty}f(\frac{1}{n})=f(\lim_{n\toinfty}\frac{1}{n})=f(0)=0$$
		\end{exmp*}

		\subsection{Squeeze Theorem}

		If $a_n\leq b_n\leq c_n\ \forall n$ and $\Lim{n\toinfty}a_n=A,\ \Lim{n\toinfty}c_n=C$, then
		$$A\leq\lim_{n\toinfty}b_n\leq C$$
		\begin{remark}
			$\Lim{n\toinfty}(1+\frac{1}{n})^n=e$
		\end{remark}
	\section{\S 11.2 Series}
		Given a sequence $\{a_n\}_{n=1}^{\infty}$, we obtain an infinite series
		by adding up all if the terms of $\{a_n\}$
		$$\sumo a_n=a_1+a_2+a_3+...$$
		\begin{def*}\textbf{Partial Sums}\\
			The $p$th partial sum of $\sumo a_n$ is $s_p=\sum_{n=1}^p a_n=a_1+a_2+...+a_p$. $s_p$ is the $p$th partial sum.
		\end{def*}
		\begin{def*}\textbf{Telescoping Series}\\
			A telescoping series is a series where "consecutive" (not always) terms cancel so that's it's possible to write a closed form of the sum of the partial sum.
		\end{def*}
		\begin{def*}\textbf{Geometric Series}\\
			An infinite series is called geometric if $a_n=a*r^n$ for $a,r\in\R$
			$$\sumo ar^n=a+ar+ar^2+ar^3+...$$
		\end{def*}
		\begin{thrm}
			Geometric series $\sumo ar^{n-1}$ converges to $\frac{a}{1-r}$ if
			$\left|r\right|<1$
		\end{thrm}
		The proof of this would take a long time to type so I won't do it right now.
		\begin{exmp*}
			\begin{align*}
				\sum_{n=2}^{\infty}ar^n&=ar^2+ar^3_ar^4+...\\
				&=r^2(a+ar+ar^2+...)\\
				&=r^2*\frac{a}{1-r}\\
				&=\frac{ar^2}{1-r}\\
			\end{align*}
			Pay attention to where your geometric series starts!
		\end{exmp*}

	\section{\S 11.3 Integral Test}
		Suppose $f(x)$ is a continuous, positive, (eventually) decreasing function on $[1,+\infty)$ with $a_n=f(n)$. Then:
		\begin{enumerate}[i]
			\item if $\int_{1}^{\infty}f(x)dx$ is convergent, then $\sumo a_n$ is also convergent
			\item if $\int_{1}^{\infty}f(x)dx$ is divergent, then $\sumo a_n$ is also divergent
		\end{enumerate}
		This idea comes from Reimann sums. If the integral of a function is less than infinity, then the series must be less than infinity as well.
		\begin{exmp*}
			$\sumo \frac{1}{n}$ is called the harmonic series.\\
			\begin{enumerate}[i)]
				\item $f(x)=\frac{1}{x}>0$, so therefore $\frac{1}{x}$ is continuous
				\item $f'(x)=\frac{-1}{x^2}<0$, so it's decreasing too
				\item $\Lim{t\toinfty}\int_1^t\frac{1}{x^2}dx=\Lim{t\toinfty}ln(t)-ln(1)\rightarrow\infty$
			\end{enumerate}
			The integral is divergent, so the series is also divergent.
		\end{exmp*}

		\subsection{P-Test}

		By using the integral test on series of the form $\sumo \frac{1}{n^p}$, we learn that if $p<1$ the series diverges and if $p>1$ the series converges.
		\begin{remark}
			If $\sumo a_n$ and $\sumo b_n$ are convergent, then
			\begin{enumerate}[i]
				\item $\sumo a_n+b_n=\sumo a_n+\sumo b_n$
				\item $\sumo a_n-b_n=\sumo a_n-\sumo b_n$
			\end{enumerate}
		\end{remark}
		\begin{remark}
			Suppose $\sumo a_n$ is convergent and $\sumo b_n$ is divergent. Then $\sumo a_n+b_n$ is divergent.
		\end{remark}

	\section{\S 11.4 Comparison Test}
		\subsection{Direct Comparison Test}
		Suppose $\sum a_n$ and $\sum b_n$ are series with positive terms.
		\begin{enumerate}[i)]
			\item If $\sum b_n$ is convergent and $a_n\leq b_n \forall n$, then $\sum a_n$ is convergent too
			\item If $\sum b_n$ is divergent and $a_n\leq b_n \forall n$, then $\sum a_n$ is divergent too
		\end{enumerate}

		\subsection{Limit Comparison Test}
		Suppose $\sum a_n$ and $\sum b_n$ are series with positive terms. If $Lim{n\toinfty} \frac{a_n}{b_n}=c$ and $c$ is non-zero and finite, then both $\sum a_n$ and $\sum b_n$ converge or diverge.\\

		If you're a computer science student, you may recognize this as Big-Theta. The idea here is that if the limit of a function divided by another function is 0, then the function on the bottom must grow faster. If the limit is $\infty$, then the function on the top must grow faster. However, if both functions grow at roughly the same rate, the limit will be some constant $c$.\\\\ This is the relationship that the limit comparison test exploits. If the limit is $c$ then $a_n$ and $b_n$ grow at roughly the same rate. For this reason if we have a series $\sum a_n$ that we want to test for convergence we can pick a series $\sum b_n$ that we know a lot about, such as the harmonic series, a p-series, etc. If we can show that $a_n$ grows at the same rate as $b_n$ we can say $a_n$ must converge (or diverge) if $b_n$ also converges (or diverges).

	\section{\S 11.5 Alternating Series Test}
		If the alternating series $\sumo (-1)^nb_n$ satisfied the following criteria:
		\begin{enumerate}[i)]
			\item $b_n\geq 0$
			\item $b_{n+1}\leq b_n \forall n\geq n_0$ (eventually)
			\item $\Lim{b_n}=0$
		\end{enumerate}
		then $\sumo (-1)^nb_n$ converges.
		\begin{exmp*}
			$\sumo (-1)^n\frac{1}{\sqrt{n^2+2}}$\\
			Finding the first derivative of $b_n$ gives $\frac{n}{(n^2+2)^{3/2}}$, which is less than 0 so $b_n$ is decreasing, and the limit of $b_n$ is 0. Therefore by AST, the series is convergent.
		\end{exmp*}
	\section{\S 11.6 Absolute Convergence}
		\begin{def*}
			A series $\sumo a_n$ is called absolutely convergent if $\sumo\left|a_n\right|$ is convergent.
		\end{def*}
		\begin{def*}
			A series $\sumo a_n$ is called conditionally convergent if $\sumo\left|a_n\right|$ is divergent but $\sumo a_n$ is convergent.
		\end{def*}
		\begin{exmp*}
			Determine if $\sumo \frac{sin(n)}{n^2}$ is convergent or divergent\\\\
			This function isn't alternating because its period is $2\pi$. It's also not positive, so we can't use our other tests. We need to test for absolute convergence with the absolute value of $b_n$.\\
			$\left|sin(n)\right|\leq 1\Rightarrow \left|\frac{sin(n)}{n^2}\right|\leq \frac{1}{n^2}$\\
			This is a convergent p-series, therefore the series is absolutely convergent.
		\end{exmp*}
	\subsection{Ratio and Root Tests}
		\textbf{Ratio Test}
		For the limit $\Lim{n\toinfty}\left|\frac{a_{n+1}}{a_n}\right|=L$:
		\begin{enumerate}[i)]
			\item if $L<1$, then $\sumo a_n$ is absolutely convergent
			\item if $L>1$, then $\sumo a_n$ is divergent
			\item if $L=1$, then the test is inconclusive
		\end{enumerate}
		In theory this makes sense, because for a series to converge the next value in the series must be less than the previous and this relationship must be true as $n$ reaches infinity.
		\begin{proof}
			Proof of part i:\\
			Suppose $\Lim{n\toinfty} \lvert \frac{a_{n+1}}{a_n} \rvert=L<1$, so that $\exists$ numbers $k,r$ such that
			$$\left|\frac{a_{n+1}}{a_n}\right|<r<1\ \forall\ n\geq k$$
			$$\Rightarrow \left|a_{n+1}\right|<r\left|a_n\right|$$
			$$\Rightarrow \left|a_{n+2}\right|<r\left|a_{n+1}\right|<r^2\left|a_n\right|$$
			$$\Rightarrow \sum\left|a_{n+k}\right|\leq\sum r^n\left|{a_k}\right|$$
		\end{proof}
		\textbf{Root Test}
		For the limit $\Lim{n\toinfty}\sqrt[n]{\lvert a_n\rvert}=L$:
		\begin{enumerate}[i)]
			\item if $L<1$, then $\sumo a_n$ is absolutely convergent
			\item if $L>1$, then $\sumo a_n$ is divergent
			\item if $L=1$, then the test is inconclusive
		\end{enumerate}
	\section{\S 11.8 Power Series}
		\begin{def*}
			A power series is a series of the form
			$$\sumz c_nx^n=c_0+c_1x+c_2x^2+...$$
			Evaluating a power series at a number $x$ gives a numerical series $\sumz a_n$. Because $x$ is a variable, the convergence of the series depends on the value of $x$.\\\\
			We obtain a function $f(x)=\sumz c_nx^n$, and the domain of this function is the set of all $x\in\R$ such that the power series converges to a finite number.
		\end{def*}
		\begin{exmp*}
			The power series where $c_n=1$ is\\
			$\sumz x^n=1+x+x^2+...$\\
			This is a geometric series. Geometric series converge if their value of $r$, the difference between the terms, is between -1 and 1. Therefore we can say that the series $\sumz x^n$ converges to $\frac{1}{1-x}$ if $\left|x\right|<1$
		\end{exmp*}
		We say that $\sumz x^n$ is the power series representation of $\frac{1}{1-x}$ on $\left|x\right|<1$\\\\
		A power series centered at $x=a$ is written
		$$\sumz c_n(x-a)^n=c_0+c_1(x-a)+c_2(x-a)^2+...$$
		Notice that when we set $x=a$, the series equals $c_0$ because all other terms are multiplied by 0. \textbf{This gives the valuable information that a power series is always convergent at its center.}
		\begin{thrm}
			For a given power series $\sumz c_n(x-a)^n$ there are only 3 possibilities:
			\begin{enumerate}[i)]
				\item The series converges at the center, where $x=a$
				\item The series converges for all $x\in\R$
				\item There exists a radius (abbreviated R) such that the series converges for $x-a<R$ and diverges for $x-a>R$
			\end{enumerate}
		\end{thrm}
		Power series that fit the third definition have both a \textbf{radius of convergence} and \textbf{interval of convergence}. Beginning at $x=a$, for values of $x$ between $a+R$ and $a-R$, the series converges. The interval of convergence gives specific information about those endpoints. Sometimes the series converges for both, one, or neither of its endpoints. This is represented by a ( or ) if the endpoint doesn't result is convergence or a [ or ] if it does.\\\\
		The \textbf{Ratio Test} has a lot of use with power series. It is used to find the ROC and IOC. This illustrates why.
		\begin{exmp*}
			Find the ROC and IOC of $\sumz \frac{x^n}{n^n}$\\
			Use the ratio test\\
			$$\Lim{n\toinfty} \lvert\frac{x^{n+1}}{(n+1)^{n+1}}\cdot\frac{n^n}{x^n}\rvert<1$$
			$$\Lim{n\toinfty}\lvert x\cdot\frac{n^n}{(n+1)^{n+1}}\rvert$$
			$$\lvert x\rvert\Lim{n\toinfty}\lvert\frac{1}{n+1}\cdot(\frac{n}{n+1})^n\rvert=0$$
			$\frac{1}{n+1}$ has limit of 0 and $(\frac{n}{n+1})^n$ has a limit of $\frac{1}{e}$. The ratio test states that in order for the series to converge, the limit must be less than 1. In this case, no matter what the value of $x$ is the limit will always be 0, which is less than 1. Therefore this power series converges for all values of $x$\\
			ROC=$\infty$ and IOC=($-\infty, +\infty$)
		\end{exmp*}
	\section{\S 11.9 Representation}
		We stated previously that $\frac{1}{1-x}=\sumz x^n$. We can exploit this in order to represent a variety of functions as power series.
		\begin{exmp*}
			Here are a few examples of rewriting functions in this way
			$$\frac{1}{1+x}=\frac{1}{1-(-x)}=\sumz (-x)^n=\sumz (-1)^nx^n$$
			true when $\lvert x\rvert<1$
			$$\frac{1}{1-2x}=\sumo (2x)^n$$
			true when $\lvert 2x\rvert<1\ \Rightarrow \ \lvert x\rvert<\frac{1}{2}$
			$$\frac{1}{1+x^4}=\frac{1}{1-(-x)^4}=\sumz (-1)^nx^{4n}$$
			true when $\lvert x^4\rvert<1\ \Rightarrow \ \lvert x\rvert<1$
		\end{exmp*}
		Since we can do this, we are also able to write the power series for functions whose integrals or derivative ressemble $\frac{1}{1-x}$ such as $\ln{x}$ and $\arctan{x}$. We do this by finding the power series for the integral or derivative, then (respective) differentiate or integrate that series to find the power series of the original function.
	\section{\S 11.10 Taylor and Maclaurin Series}
		Taylor and Maclaurin series allow us to find a power series representation of any given function $f(x)$ even if its derivative or antiderivative isn't close to the form $\frac{1}{1-x}$.\\\\
		Suppose $f(x)=\sumz c_n(x-a)^n,\ \left|x-a\right|<R$
		$$f(a)=c_0+0\ \Rightarrow\ c_0=f(a)$$
		$$f'(a)=\frac{d}{dx}(c_0+c_1(x-a)+c_2(x-a)^2+...)=c_1+2c_2(x-a)+3c_3(x-a)^2+...$$
		$$\Rightarrow\ f'(a)=c_1+0+0+...\Rightarrow\ f'(a)=c_1$$
		From this above pattern we can deduce that:
		$$f''(a)=2c_2\Rightarrow\ c_2=\frac{f''(a)}{2}$$
		$$f'''(a)=3!c_3\Rightarrow\ c_3=\frac{f'''(a)}{3!}$$
		Therefore the power series (Taylor series) that represents/equals $f(x)$ can be written as:
		$$\sumz \frac{f^n(a)(x-a)^n}{n!}$$

		There are three main Maclaurin series that are important to know/memorize:\\
		\textbf{$e^x$}
		$$\sumz \frac{x^n}{n!}=1+x+\frac{x^2}{2}+\frac{x^3}{3!}+...$$
		\textbf{$\sin{x}$}
		$$\sumz \frac{(-1)^nx^{2n+1}}{(2n+1)!}=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+...$$
		\textbf{$\cos{x}$}
		$$\sumz \frac{(-1)^nx^{2n}}{(2n)!}=1-\frac{x^2}{2}+\frac{x^4}{4!}-\frac{x^6}{6!}+...$$
		All of these converge to the true value of the functions they represent. This can we verified using the ratio test.

		\subsection{Remainders}

		Suppose we only compute a finite number of terms from a Taylor/Maclaurin series. How far is this "finite" series from the true value?\\\\
		Suppose we deconstruct the standard form of a Taylor series:
		$$f(x)=\sumz \frac{f^n(a)(x-a)^n}{n!}=\sum_{n=0}^p \frac{f^n(a)(x-a)^n}{n!}+\sum_{n=p+1}^{\infty} \frac{f^n(a)(x-a)^n}{n!}$$
		\textbf{As long as the second term of this is small, $f(x)$ can be approximated using just the first term. Since the series must converge in order to equal the function and convergent series have terms that generally decrease in size as $n$ becomes larger, for many values of $p$ we will have an acceptable amount of error}\\\\

		For convenience's sake:
		$$T_p(x)=\sum_{n=0}^p \frac{f^n(a)(x-a)^n}{n!},\ R_p(x)=\sum_{n=p+1}^{\infty} \frac{f^n(a)(x-a)^n}{n!}$$

		\begin{thrm} If $f(x)=T_p(x)+R_p(x)$ where $T_p(x)$ is the $p$th degree Taylor polynomial of $f(x)$ centered at $a$ and $\Lim{p\toinfty} R_p(x)=0$ on $\lvert x-a\rvert<ROC$, then $f(x)$ equals its Taylor series on $\lvert x-a\rvert<ROC$
		\end{thrm}

		\begin{thrm}$$\lvert R_p(x)\rvert\leq \frac{f^{p+1}(z)(x-a)^{p+1}}{(p+1)!}$$
			Where $z$ equals the value between $x-a$ and $x+a$ that causes this expression to have its largest possible value (and therefore the largest possible difference from the true value of the function $f(x)$)
		\end{thrm}

		The proof of the $p=1$ case of this involves calling $f''(z)=M$ (for $x=max(x-a,x+a)$) and then integrating this twice.
		$$\int_a^x f''(t)\ dt \leq \int_a^x M\ dt\ \Rightarrow f'(x)-f'(a) \leq M(x-a)$$
		$$\int_z^x f'(t)-f'(a)\ dt \leq \int_a^x M(t-a)\ dt \Rightarrow f(x)-f(a)-f'(a)(x-a) \leq \frac{M(x-a)^2}{2}$$
		$$\Rightarrow \lvert f(x)-T_1(x)\rvert \leq \frac{M(x-a)^2}{2}$$
		However, the LHS equals $\lvert R_1(x)\rvert$
		$$\Rightarrow \lvert R_p(x)\rvert \leq \frac{f^{p+1}(z)(x-a)^{p+1}}{(p+1)!}$$

		\begin{center}\textbf{This is known as the Lagrange form of the remainder}
		$$R_p(x)=\frac{f^{p+1}(z)(x-a)^{p+1}}{(p+1)!}$$\end{center}

		\begin{exmp*}
			Find a Taylor polynomial which approximates $\sin{\frac{1}{10}}$ to $4$ decimal places.\\\\
			We want $R_p(\frac{1}{10})$ to be less than $\frac{1}{10000}$. We must solve the inequality
			$$\frac{f^{p+1}(z)x^{p+1}}{(p+1)!} \leq \frac{1}{10000}$$
			There are a few routes you can take with a question like this. I have decided to start at $p=2$ and see if it will make the inequality true. The 3rd derivative of $\sin{x}$ is $-\cos{x}$.
			$$\frac{-\cos{(z)}x^3}{3!} \leq \frac{1}{10000}$$
			$$\frac{-\cos{(z)}(\frac{1}{10})^3}{6} \leq \frac{1}{10000}$$
			Multiply each side by $(\frac{1}{10})^{-3}$.
			$$\lvert\frac{-1}{6}\rvert \leq \frac{1}{10}$$
			It doesn't look like $p=2$ will work, let's try $p=3$. The 4th derivative of $\sin{x}$ is $\sin{x}$.
			$$\frac{\sin{(z)}x^4}{4!} \leq \frac{1}{10000}$$
			$$\frac{\sin{(z)}(\frac{1}{10})^4}{24} \leq \frac{1}{10000}$$
			$$\frac{\sin{(z)}}{24} \leq 1$$
			The only way for this to not be true is if $\sin{z}=\sin{\frac{1}{10}}>24$ ($z$ will be $\frac{1}{10}$ because that's the value of $z$ that makes the function larges in this range). This is impossible because $\sin$ has an upper bound of $1$. Therefore we need a polynomial of at least degree $3$.\\
			A polynomial that approximates $\sin{\frac{1}{1}}$ to $4$ decimal places is $x-\frac{x^3}{3!}$. The true value of $\sin{\frac{1}{10}}$ is $0.0998334166$ and our approximation gives $0.0998\overline{3}$
		\end{exmp*}

		\begin{exmp*}
			Find the Maclaurin series of $F(x)=\int e^{-x^2}$\\\\
			The only way to do this is with power series.
			$$e^x=\sumz \frac{x^n}{n!}\ \forall\ x\in\R$$
			$$\Rightarrow e^{-x}=\sumz \frac{(-x)^n}{n!}$$
			$$\Rightarrow e^{-x^2}=\sumz \frac{(-1)^nx^{2n}}{n!}$$
			Now we just need to integrate this by using the rule that $\int x^n = \frac{x^{n+1}}{n+1}$
			$$\Rightarrow \int e^{-x^2}=\int \sumz \frac{(-1)^nx^{2n}}{n!} = \sumz \frac{(-1)^nx^{2n+1}}{n!(2n+1)}+C$$
		\end{exmp*}

		\subsection{Limits using power series}

		Try to compute $\Lim{x\rightarrow 0}\frac{\sin{x^2}}{x}$

		$$\sin{x}=\sumz \frac{(-1)^nx^{2n+1}}{(2n+1)!}\ \Rightarrow\ \sin{x^2}=\sumz \frac{(-1)^nx^{4n+2}}{(2n+1)!}$$
		Now rewrite the limit using the long-form of the series.
		$$\Lim{x\rightarrow 0}\frac{x^2-\frac{x^6}{3!}+\frac{x^10}{5!}-...}{x}$$
		Divide it all by $x$
		$$\Lim{x\rightarrow 0} x-\frac{x^5}{3!}+\frac{x^9}{5!}-...=0$$
		A hint for problems like these is to center the series at whatever the value of $x$ is approaching (0, in this case)

		\subsection{$\times$ and $\div$ of Power Series}

		\begin{thrm}Suppose we have two power series\\
			$$f(x)=\sum a_n(x-a)^n, \ \lvert x-a\rvert<R_1$$
			$$g(x)=\sum b_n(x-a)^n, \ \lvert x-a\rvert<R_2$$
			Then:
			$$f(x)+g(x)= \sum (a_n+b_n)(x-a)^n, \ \lvert x-a\rvert<min(R_1,R_2)$$
			$$f(x)g(x)=(\sum a_n(x-a)^n)(\sum b_n(x-a)^n), \ \lvert x-a\rvert<min(R_1,R_2)$$
			And, if $g(a)\neq 0$:
			$$\frac{f(x)}{g(x)}=\frac{\sum a_n(x-a)^n}{\sum b_n(x-a)^n}$$
			for $\lvert x-a\rvert<r$, for some $r$
		\end{thrm}
		\begin{exmp*}For example, to find the first three non-zero terms of $f(x)=\sin{x}\cos{x}$ we would have to find the sum of all multiples of terms in their series that had the three smallest degrees. In this case:
			$$(x-\frac{x^3}{3!}+\frac{x^5}{5!})(1-\frac{x^2}{2!}+\frac{x^4}{4!})$$
			$$=x-x^3(\frac{1}{6}+\frac{1}{2})+x^5(\frac{1}{120}+\frac{1}{24}+\frac{1}{12})$$
		\end{exmp*}
\end{document}
